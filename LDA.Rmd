---
title: "LDA"
output: html_document
date: "2024-05-28"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Set up 
## Data import
```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(rstudioapi)
library(psych)
library(deSolve)  
library(ggplot2)   
library(nlme)     
library(lme4)     
library(zoo)       
library(reshape2)  
library(plyr) 
library(dplyr)
library(afex)
library(tidyr)
library(sdamr)
library(lmtest)
library(lavaan)
library(car)
library(emmeans)

packages <- c(
  "ggplot2", "nlme", "lme4", "zoo", "reshape2", "plyr", 
  "dplyr", "afex", "tidyr", "sdamr", "lmtest", "lavaan", 
  "car", "emmeans"
)

# Function to install packages if not already installed
install_if_missing <- function(pkg) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg, dependencies = TRUE)
    library(pkg, character.only = TRUE)
  }
}

# Install and load all required packages
lapply(packages, install_if_missing)

```

# Data pre-processing
## Filtering data
```{r}
CEDS <- read.csv("Data/CEDS.csv")

all_data <- CEDS %>%
  select(ID, Saliva1Time, Saliva2Time, Saliva3Time, Saliva4Time, Saliva5Time, Saliva6Time, mdespa, mdesta, mdesxa, intspa, intsta, INTSXA, MDEDXPA, DYSDXPA, PulseAv1:PulseAv5, CCSC01:CCSC26, tclesa, echrdpa, SESA, riskHI, BP1Time:BP5Time, EXTSXA)

all_data <- all_data %>%
  filter(!if_any(starts_with("BP"), is.na))

all_data <- all_data %>%
  filter(!if_all(everything(), is.na))

all_data <- all_data %>%
  rename(
    mdd_p = mdespa,
    mdd_t = mdesta,
    mdd_both = mdesxa,
    int_p = intspa,
    int_t = intspa,
    int_both = INTSXA,
    mdd_cutoff = MDEDXPA,
    dys_cuttoff = DYSDXPA,
    ext_both = EXTSXA,
    trauma = tclesa,
    ses = SESA,
    fin_hardship = echrdpa,
    act1 = CCSC01,
    av1 = CCSC02,
    act2 = CCSC03,
    act3 = CCSC04,
    av2 = CCSC05,
    supp1 = CCSC06,
    av3 = CCSC07,
    act4 = CCSC08,
    av4 = CCSC09,
    supp2 = CCSC10,
    act5 = CCSC11,
    distr1 = CCSC12,
    supp3 = CCSC13,
    act6 = CCSC14,
    distr2 = CCSC15,
    act7 = CCSC16,
    act8 = CCSC17,
    supp4 = CCSC18,
    av5 = CCSC19,
    distr3 = CCSC20,
    act9 = CCSC21,
    act10 = CCSC22,
    act11 = CCSC23,
    av6 = CCSC24,
    distr4 = CCSC25,
    act12 = CCSC26,
    starting_cortisol = Saliva1Time,
    t2 = Saliva2Time,
    t3 = Saliva3Time,
    t4 = Saliva4Time,
    t5 = Saliva5Time, 
    t6 = Saliva6Time,
    starting_BP = BP1Time
  )
```

## clearning coping data
```{r}
selected_columns <- c("act1", "act2", "act3", "act4", "act5", "act6","act7", "act8", "act9","act10","act11", "act12", "av1", "av2", "av3", "av4", "av5", "av6", "distr1", "distr2", "distr3", "distr4", "supp1", "supp2", "supp3", "supp4")

# to numeric 
all_data <- all_data %>%
  mutate(across(all_of(selected_columns), ~case_when(
    . == "never" ~ 1,
    . == "sometimes" ~ 2,
    . == "often" ~ 3,
    . == "most of the time" ~ 4,
  )))
# average for each strategy
active_items <- c("act1", "act2", "act3", "act4", "act5", "act6","act7", "act8", "act9","act10","act11", "act12")
all_data$active_coping <- rowSums(all_data[, active_items], na.rm = TRUE)

avoidance_items <- c("av1", "av2", "av3", "av4", "av5", "av6")
all_data$avoidant_coping <- rowSums(all_data[, avoidance_items], na.rm = TRUE)

distraction_items <- c("distr1", "distr2", "distr3", "distr4")
all_data$distracting_coping <- rowSums(all_data[, distraction_items], na.rm = TRUE)

supportive_items <- c("supp1", "supp2", "supp3", "supp4")
all_data$supportive_coping <- rowSums(all_data[, supportive_items], na.rm = TRUE)
```

# Data exploration
## Blood pressure recovery 
```{r}
exploration <- all_data %>%
  select(starting_cortisol, t3, t4, t5, t6, starting_BP, BP3Time, BP4Time, BP5Time, PulseAv3, PulseAv4, PulseAv5, int_both, mdd_both, ID, supportive_coping, distracting_coping, active_coping, avoidant_coping, fin_hardship, ext_both)

exploration_BP <- exploration %>%
  pivot_longer(
    cols = starts_with("BP"),
    names_to = "time",
    values_to = "BP")

raincloud_BP <- plot_raincloud(exploration_BP, BP, groups = time)

# Define the relative path to the 'Figure' directory
output_path <- "Figure/raincloud_BP.png"

# Save the plot to the 'Figure' directory
ggsave(filename = output_path, plot = raincloud_BP, width = 8, height = 6)

```

## Cortisol recovery
```{r}
exploration_cortisol <- exploration %>%
  pivot_longer(
    cols = starts_with("t"),
    names_to = "time",
    values_to = "cortisol")

raincloud_Cor <- plot_raincloud(exploration_cortisol, cortisol, groups = time)

# Define the relative path to the 'Figure' directory
output_path <- "Figure/raincloud_Cor.png"

# Save the plot to the 'Figure' directory
ggsave(filename = output_path, plot = raincloud_Cor, width = 8, height = 6)

```

## Heart rate recovery
```{r}
exploration_HR <- exploration %>%
  pivot_longer(
    cols = starts_with("PulseAv"),
    names_to = "time",
    values_to = "HR")

raincloud_HR <- plot_raincloud(exploration_HR, HR, groups = time)

output_path <- "Figure/raincloud_HR.png"

ggsave(filename = output_path, plot = raincloud_HR, width = 8, height = 6)
```

# Statistical analysis 
## Filtering out outliers
```{r}
# Blood pressure 
Q1_1 <- quantile(exploration$BP3Time, probs=c(.25, .75), na.rm = TRUE)
iqr1 <- IQR(exploration$BP3Time, na.rm = TRUE)
excluded_BP <- subset(exploration, exploration$BP3Time > (Q1_1[1] - 1.5*iqr1) & exploration$BP3Time < (Q1_1[2]+1.5*iqr1))

Q1_2 <- quantile(exploration$BP4Time, probs=c(.25, .75), na.rm = TRUE)
iqr2 <- IQR(exploration$BP4Time, na.rm = TRUE)
excluded_BP <- subset(exploration, exploration$BP4Time > (Q1_2[1] - 1.5*iqr2) & exploration$BP4Time < (Q1_2[2]+1.5*iqr2))

Q1_3 <- quantile(exploration$BP4Time, probs=c(.25, .75), na.rm = TRUE)
iqr3 <- IQR(exploration$BP4Time, na.rm = TRUE)
excluded_BP <- subset(exploration, exploration$BP4Time > (Q1_3[1] - 1.5*iqr3) & exploration$BP4Time < (Q1_3[2]+1.5*iqr3))

Q1_4 <- quantile(exploration$starting_BP, probs=c(.25, .75), na.rm = TRUE)
iqr4 <- IQR(exploration$BP4Time, na.rm = TRUE)
excluded_BP <- subset(exploration, exploration$BP4Time > (Q1_4[1] - 1.5*iqr4) & exploration$BP4Time < (Q1_4[2]+1.5*iqr4))

# Cortisol
Q1_1 <- quantile(exploration$starting_cortisol, probs=c(.25, .75), na.rm = TRUE)
iqr1 <- IQR(exploration$starting_cortisol, na.rm = TRUE)
excluded_cortisol <- subset(exploration, exploration$starting_cortisol > (Q1_1[1] - 1.5*iqr1) & exploration$starting_cortisol < (Q1_1[2]+1.5*iqr1))

Q1_2 <- quantile(exploration$t3, probs=c(.25, .75), na.rm = TRUE)
iqr2 <- IQR(exploration$t3, na.rm = TRUE)
excluded_cortisol <- subset(exploration, exploration$t3 > (Q1_2[1] - 1.5*iqr2) & exploration$t3 < (Q1_2[2]+1.5*iqr2))

Q1_3 <- quantile(exploration$t4, probs=c(.25, .75), na.rm = TRUE)
iqr3 <- IQR(exploration$t4, na.rm = TRUE)
excluded_cortisol <- subset(exploration, exploration$t4 > (Q1_3[1] - 1.5*iqr3) & exploration$t4 < (Q1_3[2]+1.5*iqr3))

Q1_4 <- quantile(exploration$t5, probs=c(.25, .75), na.rm = TRUE)
iqr4 <- IQR(exploration$t5, na.rm = TRUE)
excluded_cortisol <- subset(exploration, exploration$t5 > (Q1_4[1] - 1.5*iqr4) & exploration$t5 < (Q1_4[2]+1.5*iqr4))
```

## LME with blood pressure
```{r}
BP_long <- excluded_BP %>% # convert data to long form
  pivot_longer(
    cols = starts_with("BP"),
    names_to = "time",
    values_to = "BP")

BP_long$time <- as.factor(BP_long$time) # time to factor
contrasts(BP_long$time) <- contr.poly(3) # polynomial contrasts

# model based on theory: predicting BP based on time * coping interaction, allowing for random intercepts and controlling for starting BP
mod1_BP <- afex::mixed(BP ~ time * supportive_coping + (1|ID), set_data_arg = TRUE, check_contrasts = FALSE, data=BP_long)
summary(mod1_BP)
anova(mod1_BP, type=3)

#calculating effect size 
effectsize::eta_squared(mod1_BP)

# intercept only model
mod2_BP <- afex::mixed(BP ~ 1 + (1|ID), set_data_arg = TRUE, check_contrasts = FALSE, data=BP_long)
anova(mod1_BP, mod2_BP) # anova results show theoretical model results in a significantly better fit for the data 

# model with only time 
mod3_BP <- afex::mixed(BP ~ time + (1|ID), set_data_arg = TRUE, check_contrasts = FALSE, data=BP_long)
anova(mod1_BP, mod3_BP) # AIC and BIC not big difference 

# model with only coping
mod4_BP <- afex::mixed(BP ~ supportive_coping + (1|ID), set_data_arg = TRUE, check_contrasts = FALSE, data=BP_long)
anova(mod1_BP, mod4_BP) # theoretical model significantly better 

```
## Examining the interaction (emm)
```{r}
mod1 <- lme4::lmer(BP ~ time * supportive_coping + (1|ID), data=BP_long)
mod1_emm <- emmeans(mod1, ~ time * supportive_coping) # EMMs
# Pairwise comparison
mod1_pairwise <- pairs(mod1_emm, adjust = "Tukey")
summary(mod1_pairwise)

# Convert estimated marginal means to a data frame
emm_df <- as.data.frame(mod1_emm)

# Plot the interaction
ggplot(emm_df, aes(x = time, y = emmean, color = supportive_coping, group = supportive_coping)) +
  geom_line(size = 1.2) +  # Thicker lines
  geom_point(size = 3) +  # Larger points
  labs(
    title = "Figure 2: Interaction Plot of Time and Supportive Coping on BP",
    x = "Time",
    y = "Estimated Marginal Mean of BP",
    color = "Supportive Coping"
  ) +
  theme_minimal(base_size = 15) +  # Use a minimal theme with a larger base font size
  theme(
    plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),  # Center and bold the plot title
    axis.title = element_text(size = 16),  # Larger axis titles
    legend.title = element_text(size = 16),  # Larger legend title
    legend.text = element_text(size = 14)  # Larger legend text
  )

# Save the plot with improved dimensions and resolution
ggsave("Figure/Figure2.png", width = 10, height = 6, dpi = 300)

```

## Examining the interaction (categorisation)
```{r}
# Use median to divide into high vs. low coping group 
median_value <- median(BP_long$supportive_coping)
BP_long$supp_class <- ifelse(BP_long$supportive_coping > median_value, "high", "low")
sum(BP_long$supp_class=="high")
sum(BP_long$supp_class=="low")


BP_long$supp_class <- as.factor(BP_long$supp_class)
contrasts <- matrix(c(-1, 1), ncol = 1)
contrasts(BP_long$supp_class) <- contrasts
mod2 <- afex::mixed(BP ~ time * supp_class + (1|ID), set_data_arg = TRUE, check_contrasts = FALSE, data=BP_long)
effectsize::eta_squared(mod1_BP)
anova(mod2)
summary(mod2)

mod2_emm <- emmeans(mod2, ~ time * supp_class)
mod1_pairwise <- pairs(mod2_emm, adjust = "Tukey")
summary(mod1_pairwise)

interaction_plot <- emmip(mod2, supp_class ~ time, CIs = TRUE) +
  theme_minimal(base_size = 15) +
  ggtitle("Figure 3: Interaction") + 
  theme(
    plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),  # Center and bold the plot title
    axis.title = element_text(size = 16),  # Larger axis titles
    legend.title = element_text(size = 16),  # Larger legend title
    legend.text = element_text(size = 14)  # Larger legend text
  )
interaction_plot

ggsave("Figure/Figure3.png", plot = interaction_plot, width = 10, height = 6)

```

## Model assumption testing 
```{r}
# Extract residuals and fitted values
residuals <- residuals(mod1_BP$full_model)
fitted_values <- fitted(mod1_BP$full_model)

# 1. Linearity
# Plot residuals vs. fitted values
residuals_vs_fitted_plot <- ggplot(data = data.frame(fitted = fitted_values, residuals = residuals), aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, col = "red") +
  labs(title = "Figure 4: Residuals vs Fitted", x = "Fitted values", y = "Residuals")

ggsave("Figure/Figure4.png", plot = residuals_vs_fitted_plot, width = 10, height = 6)

# 2. Normality of Residuals
# Q-Q plot of residuals
qqnorm_plot <- ggplot(data = data.frame(residuals = residuals), aes(sample = residuals)) +
  stat_qq() +
  stat_qq_line(col = "red") +
  labs(
    title = "Figure 1a: Q-Q Plot of Residuals to Assess Normality",
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  ) +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),  # Center and bold the plot title
    axis.title = element_text(size = 16),  # Larger axis titles
    axis.text = element_text(size = 14)   # Larger axis text
  )

# Save the Q-Q plot
s
# Shapiro-Wilk test for normality
shapiro.test(residuals)

# 3. Homoscedasticity
# Plot residuals vs. fitted values
homoscedasticity_plot <- ggplot(data = data.frame(fitted = fitted_values, abs_residuals = abs(residuals)), aes(x = fitted, y = abs_residuals)) +
  geom_point(size = 2, alpha = 0.6) +  # Adjust point size and add transparency
  geom_hline(yintercept = 0, col = "red", size = 1) +  # Adjust line size for better visibility
  labs(
    title = "Figure 1b: Residuals vs. Predicted Plot to Assess Homoscedasticity",
    x = "Fitted values",
    y = "Absolute Residuals"
  ) +
  theme_minimal(base_size = 15) +  # Use a minimal theme with a larger base font size
  theme(
    plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),  # Center and bold the plot title
    axis.title = element_text(size = 16),  # Larger axis titles
    axis.text = element_text(size = 14),  # Larger axis text
    legend.title = element_text(size = 16),  # Larger legend title
    legend.text = element_text(size = 14)  # Larger legend text
  )

# Save the homoscedasticity plot
ggsave("Figure/Homoscedascity.png", plot = homoscedasticity_plot, width = 10, height = 6, dpi = 300)

# Breusch-Pagan test
bptest(lm(residuals ~ fitted_values)) 
#the residuals appear to have constant variance, and the assumption of homoscedasticity is met.

# 5. Random Effects Distribution
# Q-Q plot of random effects
random_effects <- ranef(mod1_BP$full_model)$ID[,1]
qqnorm(random_effects)
qqline(random_effects, col = "red")
```
>>>>>>> 315f5abcb980847c0984a7157d1561a2aa104ee4

### non-linearity and auto correlation in residuals
```{r}
# Create a data frame with the residuals and fitted values
residuals_data <- data.frame(time = BP_long$time, residuals = residuals, ID = BP_long$ID)

ggplot(data = residuals_data, aes(x = time, y = residuals, group = ID)) +
  geom_line() +
  labs(title = "Residuals over Time", x = "Time", y = "Residuals")

acf(residuals, main = "ACF of Residuals")

pacf(residuals, main = "PACF of Residuals")


mod1_BP_poly <- afex::mixed(BP ~ poly(time, 2) * supportive_coping + (1|ID), set_data_arg = TRUE, check_contrasts = FALSE, data = BP_long)
summary(mod1_BP_poly)
mod1_BP_ar1 <- lme(BP ~ time * supportive_coping, random = ~ 1 | ID, correlation = corAR1(), data = BP_long)
summary(mod1_BP_ar1)

anova(mod1_BP, mod1_BP_ar1, mod1_BP_poly)
AIC(mod1_BP, mod1_BP_ar1, mod1_BP_poly)
```


### Linearity example
```{r}
# Load necessary libraries
library(ggplot2)
library(lme4)

# Simulate data
set.seed(123)
n <- 100
x <- rnorm(n)
y <- 2 * x + rnorm(n)
data <- data.frame(x = x, y = y)

# Fit a linear model
model <- lm(y ~ x, data = data)

# Extract residuals and fitted values
residuals <- resid(model)
fitted_values <- fitted(model)

# Create a Residuals vs. Fitted plot
ggplot(data = data.frame(fitted = fitted_values, residuals = residuals), aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, col = "red") +
  labs(title = "Residuals vs Fitted Values", x = "Fitted Values", y = "Residuals") +
  theme_minimal()

```

